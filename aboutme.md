---
layout: page
title: About Me
---

# Anya Martin

I am an ethnographer and doctoral student in Georgia Tech's [School of Interactive Computing](https://www.ic.gatech.edu/), advised by [Dr. Cindy Lin](https://lincindy.com/), and I study the new and old ways that artificial intelligence is being used in environmental science. Meteorology currently centers on very large physics-based models that simulate a whole world's worth of atmosphere, but recent supermassive tech models like Huawei's [Pangu-Weather](https://www.nature.com/articles/s41586-023-06185-3) and Google's [Graphcast](http://arxiv.org/abs/2212.12794) focus less on physics and more on sheer prediction, turning the project of climate 'simulation' into something more uncertain, more efficient, and therefore more able to accomodate the increasing risk and instability of modern climate. That's the sales pitch -- the reality is that "AI" appears to climate scientists in many forms (supermassive models, Gen AI tools, internal statistical techniques), and as with many AI projects, environmental-scientific AI initiatives can struggle to see real use in practice. 

These two approaches, physics-based and machine-learning-based, use very different data/compute infrastructures and carry different professional allegiances. They also share striking similarities: physics-based models are also 'big,'  involving days-long training times and massive global datasets, and the PanguWeather and GraphCast papers both sold themselves on compute efficiency -- a far cry from traditional AI hyperscaling rhetoric! As meteorologists and data scientists negotiate the use of different methods for weather prediction, attending to the social components of these disputes allows us to learn more about when ML methods succeed and when they fail. 


# [CV][1]

[1]:{{ site.url }}/download/CV.pdf
